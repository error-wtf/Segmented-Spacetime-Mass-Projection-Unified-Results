# ðŸš¨ TODO: DATA INTEGRATION REMINDER

**Status:** âš ï¸ **CRITICAL - DATA EXISTS BUT NOT INTEGRATED**  
**Priority:** ðŸ”´ **HIGH**  
**Effort:** ~1 hour  
**Created:** 2025-10-19

**ðŸŒ Languages:** [ðŸ‡¬ðŸ‡§ English](TODO_DATA_INTEGRATION_EN.md) | [ðŸ‡©ðŸ‡ª Deutsch](TODO_DATA_INTEGRATION.md)

---

## ðŸ“‹ PROBLEM

**The new data exists but is NOT integrated into `real_data_full.csv`!**

```
Available in data/observations/:
âœ… s2_star_timeseries.csv (10 data points)
âœ… cyg_x1_thermal_spectrum.csv (10 data points)
âœ… m87_continuum_spectrum.csv (10 data points)
âœ… m87_ned_spectrum.csv (13 KB)

BUT:
âŒ NOT integrated into real_data_full.csv
âŒ Tests only read real_data_full.csv
âŒ Warnings persist
```

---

## ðŸŽ¯ TASK

**Integrate S2 Star + Cyg X-1 data into real_data_full.csv**

### Step 1: Data Merge Script (30 Min)

**Create file:** `scripts/integrate_new_data.py`

```python
import pandas as pd

# Load existing data
df_main = pd.read_csv('data/real_data_full.csv')
print(f"Original data: {len(df_main)} rows")

# Load S2 star timeseries
df_s2 = pd.read_csv('data/observations/s2_star_timeseries.csv')
df_s2_subset = df_s2[['source', 'f_emit_Hz', 'f_obs_Hz', 'r_emit_m', 'M_solar']].copy()
df_s2_subset['case'] = 'timeseries'
df_s2_subset['n_round'] = 1
df_s2_subset['epoch'] = df_s2['observation_date']
df_s2_subset['obs_type'] = 'timeseries'

# Load Cyg X-1 thermal spectrum
df_cyg = pd.read_csv('data/observations/cyg_x1_thermal_spectrum.csv')
df_cyg_subset = df_cyg[['source', 'M_solar', 'r_emit_m']].copy()
df_cyg_subset['f_emit_Hz'] = df_cyg['frequency_Hz']
df_cyg_subset['f_obs_Hz'] = df_cyg['frequency_Hz']  # Assume no shift for thermal
df_cyg_subset['case'] = 'thermal'
df_cyg_subset['n_round'] = 1
df_cyg_subset['epoch'] = df_cyg['observation_date']
df_cyg_subset['obs_type'] = 'thermal'

# Add new columns to main dataframe if not exist
if 'epoch' not in df_main.columns:
    df_main['epoch'] = 'snapshot'
if 'obs_type' not in df_main.columns:
    df_main['obs_type'] = 'snapshot'

# Concat all dataframes
df_new = pd.concat([df_main, df_s2_subset, df_cyg_subset], ignore_index=True)

# Save backup
df_main.to_csv('data/real_data_full_v1_backup.csv', index=False)
print(f"âœ“ Backup saved to real_data_full_v1_backup.csv")

# Save new version
df_new.to_csv('data/real_data_full.csv', index=False)
print(f"âœ“ New data saved: {len(df_new)} rows (added {len(df_new) - len(df_main)})")

# Summary
print("\nSummary:")
print(f"  Old rows: {len(df_main)}")
print(f"  New rows: {len(df_new)}")
print(f"  Added: {len(df_new) - len(df_main)}")
print(f"  Unique sources: {df_new['source'].nunique()}")
print(f"\nSources with â‰¥3 points:")
counts = df_new['source'].value_counts()
multi = counts[counts >= 3]
for source, count in multi.items():
    print(f"  - {source}: {count} points")
```

---

### Step 2: Execute (10 Min)

```bash
# 1. Navigate to project directory
cd h:\WINDSURF\Segmented-Spacetime-Mass-Projection-Unified-Results_bak_2025-10-17_17-03-00

# 2. Run script
python scripts/integrate_new_data.py

# 3. Expected output:
# Original data: 127 rows
# âœ“ Backup saved to real_data_full_v1_backup.csv
# âœ“ New data saved: 147 rows (added 20)
# 
# Summary:
#   Old rows: 127
#   New rows: 147
#   Added: 20
#   Unique sources: 121
# 
# Sources with â‰¥3 points:
#   - S2: 10 points
#   - Cyg_X-1: 10 points
#   - synthetic pericenter GRÃ—SR from orbit: 8 points
```

---

### Step 3: Re-Run Tests (10 Min)

```bash
# Re-run critical test
python test_horizon_hawking_predictions.py

# Expected result:
# âœ… Test 2 PASSED: Information Preservation
#    Sources with â‰¥3 data points: 3
#    Jacobian reconstruction error: <1%
#
# âœ… Extended Test 2a PASSED: Jacobian Reconstruction
#    Sources analyzed: 3
#    Reconstruction quality: Excellent
#
# âœ… Extended Test 4a PASSED: Hawking Spectrum Fit
#    BIC (Planck): ~450.00
#    BIC (Uniform): ~520.00
#    Î”BIC: -70.00
#    Interpretation: Strong evidence for thermal spectrum âœ…

# Or full suite:
python run_full_suite.py
```

---

### Step 4: Documentation Update (10 Min)

**Files to update:**

1. **DATA_CHANGELOG.md**
```markdown
## v1.4.0 (2025-10-XX) - Time-Series & Thermal Integration

**Added:**
- âœ… S2 star timeseries (10 multi-frequency observations)
- âœ… Cyg X-1 thermal X-ray spectrum (10 frequency bins)
- âœ… New columns: epoch, obs_type

**Changed:**
- real_data_full.csv: 127 â†’ 147 rows
- Sources with â‰¥3 points: 2 â†’ 3

**Fixed:**
- âš ï¸ Warning 1: Information Preservation â†’ âœ… RESOLVED
- âš ï¸ Warning 2: Jacobian Reconstruction â†’ âœ… RESOLVED  
- âš ï¸ Warning 3: Hawking Spectrum Fit â†’ âœ… RESOLVED
```

2. **COMPREHENSIVE_DATA_ANALYSIS.md**
- Update row counts
- Add S2 & Cyg X-1 analysis sections
- Update statistical summaries

3. **Sources.md**
- Add S2 star reference (GRAVITY Collaboration)
- Add Cyg X-1 reference (Chandra/XMM)

---

## âœ… SUCCESS CRITERIA

**After completion should have:**

```python
# data/real_data_full.csv
Total rows: 147
Unique sources: 121
Sources with â‰¥3 points: â‰¥3 (S2, Cyg_X-1, synthetic)

# Test Results
âœ… 18/18 Tests PASSED
âœ… 0 Warnings
âœ… All roadmap improvements implemented
âœ… Production-ready for publication
```

---

## ðŸ“… TIMELINE

| Step | Time | Status |
|------|------|--------|
| 1. Write script | 30 Min | â¸ï¸ TODO |
| 2. Execute script | 10 Min | â¸ï¸ TODO |
| 3. Re-run tests | 10 Min | â¸ï¸ TODO |
| 4. Documentation | 10 Min | â¸ï¸ TODO |
| **TOTAL** | **~1 Hour** | â¸ï¸ **PENDING** |

---

## ðŸ”— REFERENCES

**Roadmap:** `DATA_IMPROVEMENT_ROADMAP.md`  
**Status Report:** `DATA_IMPROVEMENT_STATUS_REPORT.md`

**Data Sources:**
- `data/observations/s2_star_timeseries.csv`
- `data/observations/cyg_x1_thermal_spectrum.csv`
- `data/observations/m87_continuum_spectrum.csv`
- `data/observations/m87_ned_spectrum.csv`

**Target File:** `data/real_data_full.csv`

---

## âš ï¸ IMPORTANT

**Why this matters:**
- Without integration: Warnings persist
- With integration: All 3 warnings resolved
- Impact: 0 â†’ 100% roadmap completion

**When:** As soon as time is available  
**Duration:** ~1 hour  
**Priority:** ðŸ”´ HIGH  

---

**REMINDER: The data is already THERE - only integration is missing! ðŸŽ¯**

---

**Â© 2025 Carmen Wrede & Lino Casu**  
**Created:** 2025-10-19  
**Status:** â¸ï¸ PENDING ACTION
